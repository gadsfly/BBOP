{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import threading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now, from above, integrating partial scanning again!\n",
    "\n",
    "# import sys\n",
    "# import os\n",
    "# import concurrent.futures\n",
    "# sys.path.append(os.path.abspath('../..'))\n",
    "# import pandas as pd\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "# from utlis.sync_utlis.sync_df_utlis import find_calib_file\n",
    "# from utlis.scan_engine_utlis.scan_engine_utlis import (\n",
    "#     read_failed_paths,\n",
    "#     match_date_pattern,\n",
    "#     assign_status_codes\n",
    "# )\n",
    "# from scan_engine.status_fields_config import STATUS_FIELDS_CONFIG\n",
    "\n",
    "# # # Function to scan an individual folder (for parallel processing)\n",
    "# # def scan_folder(folder_name, base_folder, failed_paths, config):\n",
    "# #     folder_path = os.path.join(base_folder, folder_name)\n",
    "# #     rec_files_data = []  # To store rec files and their status\n",
    "# #     calib_files = []  # To store calibration files\n",
    "\n",
    "# #     # Check for calibration files starting with 'calib'\n",
    "# #     for file_name in os.listdir(folder_path):\n",
    "# #         if file_name.startswith(\"calib\"):\n",
    "# #             calib_files.append(file_name)\n",
    "\n",
    "# #     # Traverse subfolders within this folder\n",
    "# #     for subfolder_name in os.listdir(folder_path):\n",
    "# #         subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "\n",
    "# #         # Check for subfolders starting with a digit (rec folders)\n",
    "# #         if os.path.isdir(subfolder_path) and subfolder_name[0].isdigit():\n",
    "# #             # Find calibration file for each subfolder\n",
    "# #             calib_file = find_calib_file(subfolder_path)\n",
    "\n",
    "# #             # Assign status codes dynamically based on the config\n",
    "# #             rec_file_data = assign_status_codes(\n",
    "# #                 folder_name, subfolder_path, calib_file, failed_paths, config\n",
    "# #             )\n",
    "\n",
    "# #             rec_file_data['rec_file'] = subfolder_name  # Add rec_file to the data\n",
    "# #             rec_files_data.append(rec_file_data)\n",
    "\n",
    "# #     return {\n",
    "# #         'date_folder': folder_name,\n",
    "# #         'calib_files': calib_files,  # Store the calibration files under date_folder level\n",
    "# #         'rec_files_data': rec_files_data  # Each rec file with its status fields\n",
    "# #     }\n",
    "\n",
    "# # # Parallel version of the original log_folder_to_parquet function, with partial scan now.\n",
    "# # # def log_folder_to_parquet(base_folder, parquet_file, failed_paths_file, config):\n",
    "# # #     # Read manually inputted failed paths\n",
    "# # #     failed_paths = read_failed_paths(failed_paths_file)\n",
    "\n",
    "# # #     # Read the existing log to get already processed date folders\n",
    "# # #     existing_df = pq.read_table(parquet_file).to_pandas()\n",
    "# # #     logged_folders = existing_df['date_folder'].unique() if not existing_df.empty else []\n",
    "\n",
    "# # #     # Get the list of current date folders that match the date pattern and are not logged yet\n",
    "# # #     date_folders = [\n",
    "# # #         f for f in os.listdir(base_folder) \n",
    "# # #         if os.path.isdir(os.path.join(base_folder, f)) and match_date_pattern(f) \n",
    "# # #         and f not in logged_folders  # Only include new folders\n",
    "# # #     ]\n",
    "    \n",
    "# # #     # If there are no new folders, print a message and return\n",
    "# # #     if not date_folders:\n",
    "# # #         print(\"No new folders to scan.\")\n",
    "# # #         return\n",
    "\n",
    "# # #     # Use ThreadPoolExecutor for parallel folder scanning\n",
    "# # #     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "# # #         # Run scan_folder in parallel for each new date folder\n",
    "# # #         log_data = list(executor.map(scan_folder, date_folders, [base_folder] * len(date_folders), [failed_paths] * len(date_folders), [config] * len(date_folders)))\n",
    "\n",
    "# # #     # Convert the results into a DataFrame\n",
    "# # #     df = pd.json_normalize(log_data, 'rec_files_data', ['date_folder', 'calib_files'])\n",
    "\n",
    "# # #     # Dynamically ensure all relevant columns are strings based on config\n",
    "# # #     status_columns = list(config.keys())\n",
    "# # #     df[status_columns] = df[status_columns].astype(str)\n",
    "\n",
    "# # #     # Create pyarrow Table and save as Parquet\n",
    "# # #     table = pa.Table.from_pandas(df)\n",
    "# # #     pq.write_table(table, parquet_file)\n",
    "\n",
    "# # def log_folder_to_parquet(base_folder, parquet_file, failed_paths_file, config):\n",
    "# #     # Read manually inputted failed paths\n",
    "# #     failed_paths = read_failed_paths(failed_paths_file)\n",
    "\n",
    "# #     # Initialize logged folders\n",
    "# #     logged_folders = []\n",
    "\n",
    "# #     # Check if the Parquet file exists\n",
    "# #     if os.path.exists(parquet_file):\n",
    "# #         # Read the existing log to get already processed date folders\n",
    "# #         existing_df = pq.read_table(parquet_file).to_pandas()\n",
    "# #         logged_folders = existing_df['date_folder'].unique() if not existing_df.empty else []\n",
    "# #     else:\n",
    "# #         print(\"No existing Parquet file found. Running full scan.\")\n",
    "\n",
    "# #     # Get the list of current date folders that match the date pattern\n",
    "# #     date_folders = [\n",
    "# #         f for f in os.listdir(base_folder) \n",
    "# #         if os.path.isdir(os.path.join(base_folder, f)) and match_date_pattern(f)\n",
    "# #     ]\n",
    "    \n",
    "# #     # Filter for new folders not logged yet\n",
    "# #     new_folders = [f for f in date_folders if f not in logged_folders]\n",
    "\n",
    "# #     # If no new folders are found, print a message and return\n",
    "# #     if not new_folders:\n",
    "# #         print(\"No new folders to scan.\")\n",
    "# #         return\n",
    "\n",
    "# #     # Use ThreadPoolExecutor for parallel folder scanning\n",
    "# #     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "# #         # Run scan_folder in parallel for each new date folder\n",
    "# #         log_data = list(executor.map(scan_folder, new_folders, [base_folder] * len(new_folders), [failed_paths] * len(new_folders), [config] * len(new_folders)))\n",
    "\n",
    "# #     # Convert the results into a DataFrame\n",
    "# #     df = pd.json_normalize(log_data, 'rec_files_data', ['date_folder', 'calib_files'])\n",
    "\n",
    "# #     # Dynamically ensure all relevant columns are strings based on config\n",
    "# #     status_columns = list(config.keys())\n",
    "# #     df[status_columns] = df[status_columns].astype(str)\n",
    "\n",
    "# #     # Create pyarrow Table and save as Parquet\n",
    "# #     table = pa.Table.from_pandas(df)\n",
    "# #     pq.write_table(table, parquet_file)\n",
    "# #     print(\"all scannning done\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     base_folder = \"/hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ\"  # Replace with your base folder\n",
    "# #     save_path = os.path.join(base_folder, 'paret')\n",
    "# #     failed_paths_file = '/hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/mir_bundle_run/synced_folders/240914_failed_sum_test.txt'  # File containing failed paths\n",
    "\n",
    "# #     if not os.path.exists(save_path):\n",
    "# #         os.makedirs(save_path)\n",
    "\n",
    "# #     parquet_file = os.path.join(save_path, \"folder_log_encoded_numb_paralle_test_3.parquet\")  # Output Parquet file\n",
    "\n",
    "# #     # Run the full scan with parallel processing\n",
    "# #     log_folder_to_parquet(base_folder, parquet_file, failed_paths_file, STATUS_FIELDS_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log for 20240717_PMC_r1_11_50 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_16/20240717_PMC_r1_11_50/folder_log.parquet\n",
      "Log for 20240717_PMC_r2_11_00 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_16/20240717_PMC_r2_11_00/folder_log.parquet\n",
      "Log for 1686940_left_right saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_25/1686940_left_right/folder_log.parquet\n",
      "Log for 1686940_left_right_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_25/1686940_left_right_2/folder_log.parquet\n",
      "Log for 20240628_PMC_r1_11_43 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_08/20240628_PMC_r1_11_43/folder_log.parquet\n",
      "Log for 20240628_PMC_r1_11_26 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_08/20240628_PMC_r1_11_26/folder_log.parquet\n",
      "Log for 20240702_PMC_r1_12_02 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_08/20240702_PMC_r1_12_02/folder_log.parquet\n",
      "Log for 20240717_PMCr1 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240717_PMCr1/folder_log.parquet\n",
      "Log for 20240730_PMCr2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240730_PMCr2/folder_log.parquet\n",
      "Log for 20240717_PMCr2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240717_PMCr2/folder_log.parquet\n",
      "Log for 20240916v1r1_15_05_30min saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_15_05_30min/folder_log.parquet\n",
      "Log for 20240916v1r1_19_18 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_19_18/folder_log.parquet\n",
      "Log for 20240916v1r1_17_55 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_17_55/folder_log.parquet\n",
      "Log for 20240916v1r1_18_53 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_18_53/folder_log.parquet\n",
      "Log for 20240916V1r2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240916V1r2/folder_log.parquet\n",
      "Log for 20240819V1r1_20_10 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_20_10/folder_log.parquet\n",
      "Log for 241004_miniscopes saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/241004_miniscopes/folder_log.parquet\n",
      "Log for 20240819V1r1_21_05 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_21_05/folder_log.parquet\n",
      "Log for 20240916V1r1 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240916V1r1/folder_log.parquet\n",
      "Log for 20240819V1r1_21_40 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_21_40/folder_log.parquet\n",
      "Log for 20240819V1r1 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1/folder_log.parquet\n",
      "Log for 20240707-PMC-r1 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240707-PMC-r1/folder_log.parquet\n",
      "Log for 20240819_V1_r1_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819_V1_r1_2/folder_log.parquet\n",
      "Log for 20240819_V1_r1 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819_V1_r1/folder_log.parquet\n",
      "Log for 20240819-V1-r2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819-V1-r2/folder_log.parquet\n",
      "Log for 1691486NMCFS1123 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_16/1691486NMCFS1123/folder_log.parquet\n",
      "Log for 1691485RMCFF1500 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_16/1691485RMCFF1500/folder_log.parquet\n",
      "Log for 1691485RMHBN1405 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_16/1691485RMHBN1405/folder_log.parquet\n",
      "Log for 1691485RMCFS1535 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_16/1691485RMCFS1535/folder_log.parquet\n",
      "Log for 1691486NMHBN0927 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_16/1691486NMHBN0927/folder_log.parquet\n",
      "Log for 1691486NMCFF1033 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_16/1691486NMCFF1033/folder_log.parquet\n",
      "Log for 1691486_left_right_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_right_habituation/folder_log.parquet\n",
      "Log for 1691486_left_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_habituation/folder_log.parquet\n",
      "Log for 1691486_left_caffeine_1050 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_caffeine_1050/folder_log.parquet\n",
      "Log for 1691486_left_right_caffeine_1448 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_right_caffeine_1448/folder_log.parquet\n",
      "Log for 1691486_left_caffeine_1051 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_caffeine_1051/folder_log.parquet\n",
      "Log for 1691486_left_right_caffeine_1546 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_right_caffeine_1546/folder_log.parquet\n",
      "Log for 1691486_left_caffeine_1128 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_03/1691486_left_caffeine_1128/folder_log.parquet\n",
      "Log for 20240717_PMCr2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_29/20240717_PMCr2/folder_log.parquet\n",
      "Log for 240605PMC1_right_hole_11_27 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_12/240605PMC1_right_hole_11_27/folder_log.parquet\n",
      "Log for 240626V1_right_hole_10_31 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_12/240626V1_right_hole_10_31/folder_log.parquet\n",
      "Log for 1686941_left_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_27/1686941_left_2/folder_log.parquet\n",
      "Log for 1686941_right saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_27/1686941_right/folder_log.parquet\n",
      "Log for 1686941_left_right saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_27/1686941_left_right/folder_log.parquet\n",
      "Log for 1686940_left_right_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_27/1686940_left_right_2/folder_log.parquet\n",
      "Log for 1686940_right_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_27/1686940_right_2/folder_log.parquet\n",
      "Log for 1686941_left saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_27/1686941_left/folder_log.parquet\n",
      "Log for 20240819V1r2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_03/20240819V1r2/folder_log.parquet\n",
      "Log for 20240819V1r1 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_03/20240819V1r1/folder_log.parquet\n",
      "Log for 1686941_right saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_28/1686941_right/folder_log.parquet\n",
      "Log for 1686941_no_hole saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_28/1686941_no_hole/folder_log.parquet\n",
      "Log for 1686941_left_right_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_28/1686941_left_right_2/folder_log.parquet\n",
      "Log for 1686941_right_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_28/1686941_right_2/folder_log.parquet\n",
      "Log for 1686941_no_hole_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_28/1686941_no_hole_2/folder_log.parquet\n",
      "Log for 1691486_left_right_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_02/1691486_left_right_habituation/folder_log.parquet\n",
      "Log for 1691486_left_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_02/1691486_left_habituation/folder_log.parquet\n",
      "Log for 1691486_left_saline_1051 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_02/1691486_left_saline_1051/folder_log.parquet\n",
      "Log for 1691486_left_right_saline_1430 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_02/1691486_left_right_saline_1430/folder_log.parquet\n",
      "Log for 1691486_left_right_saline_1505 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_02/1691486_left_right_saline_1505/folder_log.parquet\n",
      "Log for 1691486_left_saline_1016 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_02/1691486_left_saline_1016/folder_log.parquet\n",
      "Log for 1691485RMPBF1531 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_15/1691485RMPBF1531/folder_log.parquet\n",
      "Log for 1691485RMPBS1659 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_15/1691485RMPBS1659/folder_log.parquet\n",
      "Log for 1691485RMHBN1425 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_15/1691485RMHBN1425/folder_log.parquet\n",
      "Log for 240605PMC_window2_right2holes_12_14 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_19/240605PMC_window2_right2holes_12_14/folder_log.parquet\n",
      "Log for 240605PMC_window2_right2holes_11_30 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_19/240605PMC_window2_right2holes_11_30/folder_log.parquet\n",
      "Log for 1691485_left_right_saline_16_24 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_right_saline_16_24/folder_log.parquet\n",
      "Log for 1691485_left_right_saline_15_34 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_right_saline_15_34/folder_log.parquet\n",
      "Log for 1691485_left_hole_saline_10_35 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_hole_saline_10_35/folder_log.parquet\n",
      "Log for 1691485_left_hole_saline_11_10 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_hole_saline_11_10/folder_log.parquet\n",
      "Log for 1691485_no_hole_habituation_13_59 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_no_hole_habituation_13_59/folder_log.parquet\n",
      "Log for 1691485_left_right_habituation_14_33 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_right_habituation_14_33/folder_log.parquet\n",
      "Log for 1691485_left_hole_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_hole_habituation/folder_log.parquet\n",
      "Log for 1691485_left_right_habituation_14_46 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_10/1691485_left_right_habituation_14_46/folder_log.parquet\n",
      "Log for 1691485_no_hole_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691485_no_hole_habituation/folder_log.parquet\n",
      "Log for 1691486_right_hole_caffine_16_15 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691486_right_hole_caffine_16_15/folder_log.parquet\n",
      "Log for 1691486_right_hole_caffine_16_18 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691486_right_hole_caffine_16_18/folder_log.parquet\n",
      "Log for 1691486_right_hole_habituation_14_39 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691486_right_hole_habituation_14_39/folder_log.parquet\n",
      "Log for 1691486_right_hole_caffine_15_31 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691486_right_hole_caffine_15_31/folder_log.parquet\n",
      "Log for 1691485_no_hole_caffeine_1118 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691485_no_hole_caffeine_1118/folder_log.parquet\n",
      "Log for 1691485_left_hole_habituation saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691485_left_hole_habituation/folder_log.parquet\n",
      "Log for 1691485_no_hole_caffeine_1041 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_09/1691485_no_hole_caffeine_1041/folder_log.parquet\n",
      "Log for 1691485LMCFF1045 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_11/1691485LMCFF1045/folder_log.parquet\n",
      "Log for 1691485LMHBN0953 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_11/1691485LMHBN0953/folder_log.parquet\n",
      "Log for 1691485BMCFF1505 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_11/1691485BMCFF1505/folder_log.parquet\n",
      "Log for 1691485BMCFS1547 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_11/1691485BMCFS1547/folder_log.parquet\n",
      "Log for 1691485LMCFS1129 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_11/1691485LMCFS1129/folder_log.parquet\n",
      "Log for 1691485BMHBN1359 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_11/1691485BMHBN1359/folder_log.parquet\n",
      "Log for 1686940_left2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_26/1686940_left2/folder_log.parquet\n",
      "Log for 1686940_left saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_26/1686940_left/folder_log.parquet\n",
      "Log for 1686940_no_hole_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_26/1686940_no_hole_2/folder_log.parquet\n",
      "Log for 1686940_right_2 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_26/1686940_right_2/folder_log.parquet\n",
      "Log for 1686940_no_holes saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_06_26/1686940_no_holes/folder_log.parquet\n",
      "Log for 230815PMC_no_hole_caffine saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_no_hole_caffine/folder_log.parquet\n",
      "Log for 230815PMC_left_hole_caffeine_15_32 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_left_hole_caffeine_15_32/folder_log.parquet\n",
      "Log for 230815PMC_no_hole_caffine_11_40 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_no_hole_caffine_11_40/folder_log.parquet\n",
      "Log for 230815PMC_no_hole_caffine_13_10 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_no_hole_caffine_13_10/folder_log.parquet\n",
      "Log for 230815PMC_left_hole_caffeine_16_42 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_left_hole_caffeine_16_42/folder_log.parquet\n",
      "Log for 230815PMC_left_hole_caffeine_16_37 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_left_hole_caffeine_16_37/folder_log.parquet\n",
      "Log for 230815PMC_no_hole_caffine_13_15 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_no_hole_caffine_13_15/folder_log.parquet\n",
      "Log for 230815PMC_left_hole_baseline_14_32 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_left_hole_baseline_14_32/folder_log.parquet\n",
      "Log for 230815PMC_left_hole_caffeine_16_50 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_left_hole_caffeine_16_50/folder_log.parquet\n",
      "Log for 230815PMC_no_hole_caffine_13_56 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_01/230815PMC_no_hole_caffine_13_56/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1038 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1038/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_2_1123_test saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_2_1123_test/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1439 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1439/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1054_test saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1054_test/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1459 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1459/folder_log.parquet\n",
      "Log for 1691486_right_baseline_test_1438 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_test_1438/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1500 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1500/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1025 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1025/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1046_test saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1046_test/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1029 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1029/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1349 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1349/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1035 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1035/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1353 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1353/folder_log.parquet\n",
      "Log for 1691486_no_hole_saline_1032 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_saline_1032/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1433 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1433/folder_log.parquet\n",
      "Log for 1691486_no_hole_habituation_938 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_no_hole_habituation_938/folder_log.parquet\n",
      "Log for 1691486_right_baseline_1533 saved at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_07_08/1691486_right_baseline_1533/folder_log.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utlis.sync_utlis.sync_df_utlis import find_calib_file\n",
    "from utlis.scan_engine_utlis.scan_engine_utlis import (\n",
    "    read_failed_paths,\n",
    "    match_date_pattern,\n",
    "    assign_status_codes,\n",
    ")\n",
    "from scan_engine.status_fields_config import STATUS_FIELDS_CONFIG\n",
    "\n",
    "# Import functions from utils.py\n",
    "from utlis.scan_engine_utlis.scan_log_utlis import (\n",
    "    load_scan_log,\n",
    "    save_scan_log,\n",
    "    clean_scan_log,\n",
    "    update_scan_log,\n",
    "    get_folders_to_scan\n",
    ")\n",
    "\n",
    "def scan_folder(folder_name, base_folder, failed_paths, config, rec_files_to_scan):\n",
    "    folder_path = os.path.join(base_folder, folder_name)\n",
    "    rec_files_data = []  # To store rec files and their status\n",
    "    calib_files = []  # To store calibration files\n",
    "\n",
    "    # Check for calibration files starting with 'calib'\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith(\"calib\"):\n",
    "            calib_files.append(file_name)\n",
    "\n",
    "    # Traverse subfolders within this folder\n",
    "    for subfolder_name in rec_files_to_scan:\n",
    "        subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "\n",
    "        # Check for subfolders starting with a digit (rec folders)\n",
    "        if os.path.isdir(subfolder_path) and subfolder_name[0].isdigit():\n",
    "            # Find calibration file for each subfolder\n",
    "            calib_file = find_calib_file(subfolder_path)\n",
    "\n",
    "            # Assign status codes dynamically based on the config\n",
    "            rec_file_data = assign_status_codes(\n",
    "                folder_name, subfolder_path, calib_file, failed_paths, config\n",
    "            )\n",
    "\n",
    "            rec_file_data['rec_file'] = subfolder_name  # Add rec_file to the data\n",
    "            # Add date-time for update and some future\n",
    "            rec_file_data['scan_time'] = datetime.datetime.now().isoformat()\n",
    "\n",
    "            rec_files_data.append(rec_file_data)\n",
    "\n",
    "    return {\n",
    "        'date_folder': folder_name,\n",
    "        'calib_files': calib_files,  # Store the calibration files under date_folder level\n",
    "        'rec_files_data': rec_files_data  # Each rec file with its status fields\n",
    "    }\n",
    "\n",
    "def log_folder_to_parquet_sep(base_folder, failed_paths_file, config, force_rescan_rec_files=None, rescan_threshold_days=7):\n",
    "    \"\"\"Log folders and save Parquet in subfolders with partial scan support.\"\"\"\n",
    "\n",
    "    # Paths for scan log\n",
    "    scan_log_path = os.path.join(base_folder, 'paret', 'scan_log.csv')\n",
    "\n",
    "    # Load or initialize the scan log\n",
    "    scan_log_df = load_scan_log(scan_log_path)\n",
    "\n",
    "    # Read manually inputted failed paths\n",
    "    failed_paths = read_failed_paths(failed_paths_file) if failed_paths_file else set()\n",
    "\n",
    "    # Forced rescans\n",
    "    # force_rescan_rec_files = [\n",
    "    #     # ('2023-10-01', '001'),\n",
    "    #     # ('2023-10-02', '002'),\n",
    "    #     # Add more as needed\n",
    "    # ]\n",
    "    # force_rescan_rec_files_set = set(force_rescan_rec_files)\n",
    "    \n",
    "    if force_rescan_rec_files is None:\n",
    "        force_rescan_rec_files = []\n",
    "    force_rescan_rec_files_set = set(force_rescan_rec_files)\n",
    "\n",
    "\n",
    "\n",
    "    # Rescan threshold\n",
    "    # rescan_threshold_days = 7\n",
    "\n",
    "    # Determine folders to scan\n",
    "    folders_to_scan = get_folders_to_scan(base_folder, scan_log_df, rescan_threshold_days, force_rescan_rec_files_set)\n",
    "\n",
    "    if not folders_to_scan:\n",
    "        print(\"No new or modified folders to scan.\")\n",
    "        return\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel folder scanning\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for date_folder, rec_files_to_scan in folders_to_scan.items():\n",
    "            futures.append(\n",
    "                executor.submit(\n",
    "                    scan_folder,\n",
    "                    date_folder,\n",
    "                    base_folder,\n",
    "                    failed_paths,\n",
    "                    config,\n",
    "                    rec_files_to_scan\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            folder_log = future.result()\n",
    "            date_folder = folder_log['date_folder']\n",
    "            calib_files = folder_log.get('calib_files', [])\n",
    "\n",
    "            # Ensure 'calib_files' is always a list of strings\n",
    "            calib_files = [str(f) for f in calib_files] if calib_files else []\n",
    "\n",
    "            # Process and save each experiment's log separately\n",
    "            for rec_file_data in folder_log['rec_files_data']:\n",
    "                rec_file = rec_file_data['rec_file']\n",
    "                subfolder_save_path = os.path.join(base_folder, date_folder, rec_file, \"folder_log.parquet\")\n",
    "\n",
    "                # Ensure the experiment/rec_file folder exists\n",
    "                os.makedirs(os.path.dirname(subfolder_save_path), exist_ok=True)\n",
    "\n",
    "                # Add 'date_folder' and 'calib_files' to rec_file_data\n",
    "                rec_file_data['date_folder'] = date_folder\n",
    "                rec_file_data['calib_files'] = calib_files\n",
    "\n",
    "                # Dynamically ensure all relevant columns are strings based on config\n",
    "                status_columns = list(config.keys())\n",
    "                df = pd.DataFrame([rec_file_data])\n",
    "                df[status_columns] = df[status_columns].astype(str)\n",
    "\n",
    "                # Convert the data into a DataFrame and save the Parquet file\n",
    "                table = pa.Table.from_pandas(df)\n",
    "                pq.write_table(table, subfolder_save_path)\n",
    "\n",
    "                print(f\"Log for {rec_file} saved at {subfolder_save_path}\")\n",
    "\n",
    "                # Update the scan log\n",
    "                scan_log_df = update_scan_log(scan_log_df, date_folder, rec_file)\n",
    "\n",
    "    # Clean up the scan log\n",
    "    scan_log_df = clean_scan_log(scan_log_df, base_folder)\n",
    "\n",
    "    # Save the updated scan log\n",
    "    save_scan_log(scan_log_df, scan_log_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_folder = \"/hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ\"  # Replace with your base folder\n",
    "    # save_path = os.path.join(base_folder, 'paret')\n",
    "    failed_paths_file = '/hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/mir_bundle_run/synced_folders/240914_failed_sum_test.txt'  # File containing failed paths\n",
    "\n",
    "\n",
    "    force_rescan_rec_files = [\n",
    "        # ('2023-10-01', '001'),\n",
    "        # ('2023-10-02', '002'),\n",
    "        # Add more as needed\n",
    "    ]\n",
    "    rescan_threshold_days = 7 # 7 days, but guess if i mess up i can just change it to automatically rescan all, smile... #0.1\n",
    "\n",
    "    log_folder_to_parquet_sep(base_folder, failed_paths_file, STATUS_FIELDS_CONFIG,\n",
    "                              force_rescan_rec_files=force_rescan_rec_files,\n",
    "                              rescan_threshold_days=rescan_threshold_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "mir_generate_param: string\n",
      "sync: string\n",
      "z_adjusted: string\n",
      "rec_file: string\n",
      "scan_time: string\n",
      "date_folder: string\n",
      "----\n",
      "mir_generate_param: [[\"0\"],[\"0\"],...,[\"0\"],[\"1\"]]\n",
      "sync: [[\"3\"],[\"3\"],...,[\"0\"],[\"0\"]]\n",
      "z_adjusted: [[\"0\"],[\"0\"],...,[\"2\"],[\"2\"]]\n",
      "rec_file: [[\"1686940_left_right\"],[\"1686940_left_right_2\"],...,[\"20240916v1r1_18_53\"],[\"20240916v1r1_19_18\"]]\n",
      "scan_time: [[\"2024-10-15T16:51:45.803150\"],[\"2024-10-15T16:51:45.806128\"],...,[\"2024-10-15T16:51:45.942541\"],[\"2024-10-15T16:51:45.894511\"]]\n",
      "date_folder: [[\"2024_06_25\"],[\"2024_06_25\"],...,[\"2024_10_07\"],[\"2024_10_07\"]]\n"
     ]
    }
   ],
   "source": [
    "from utlis.scan_engine_utlis.scan_engine_utlis import read_all_parquet_files_auto_exclude\n",
    "base_folder = \"/hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ\"\n",
    "\"\"\"actually can use read_all_parquet_files in cluster probably, i do not have calib folders locally so need to handle this hhh\"\"\"\n",
    "\n",
    "# Example usage\n",
    "# base_folder = \"/path/to/your/base_folder\"  # Replace with your base folder\n",
    "combined_df = read_all_parquet_files_auto_exclude(base_folder, exclude_columns = ['calib_files']\n",
    ")\n",
    "\n",
    "# Display or use the combined DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mir_generate_param    sync z_adjusted  \\\n",
      "0                False   False      False   \n",
      "1                False  FAILED      False   \n",
      "2                False  FAILED      False   \n",
      "3                False   False      False   \n",
      "4                False   False      False   \n",
      "..                 ...     ...        ...   \n",
      "101              False  FAILED      False   \n",
      "102              False   False      False   \n",
      "103              False   False      False   \n",
      "104              False   False      False   \n",
      "105              False   False      False   \n",
      "\n",
      "                                rec_file scan_time date_folder  \n",
      "0         1691486_left_right_habituation      None  2024_07_03  \n",
      "1               1691486_left_habituation      None  2024_07_03  \n",
      "2             1691486_left_caffeine_1050      None  2024_07_03  \n",
      "3       1691486_left_right_caffeine_1448      None  2024_07_03  \n",
      "4             1691486_left_caffeine_1051      None  2024_07_03  \n",
      "..                                   ...       ...         ...  \n",
      "101   230815PMC_left_hole_caffeine_16_50      None  2024_07_01  \n",
      "102      230815PMC_no_hole_caffine_13_56      None  2024_07_01  \n",
      "103                       20240717_PMCr2      None  2024_08_29  \n",
      "104  240605PMC_window2_right2holes_12_14      None  2024_07_19  \n",
      "105  240605PMC_window2_right2holes_11_30      None  2024_07_19  \n",
      "\n",
      "[106 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# import pyarrow.compute as pc\n",
    "\n",
    "# # Define a mask to identify rows with 'False' or null values in specific columns\n",
    "# mask_false_mir = pc.equal(table['mir_generate_param'], 'False')\n",
    "# mask_false_sync = pc.equal(table['sync'], 'False')\n",
    "# mask_false_z_adjusted = pc.equal(table['z_adjusted'], 'False')\n",
    "\n",
    "# mask_null_mir = pc.is_null(table['mir_generate_param'])\n",
    "# mask_null_sync = pc.is_null(table['sync'])\n",
    "# mask_null_z_adjusted = pc.is_null(table['z_adjusted'])\n",
    "\n",
    "# # Combine the masks using multiple pc.or_() calls\n",
    "# mask = pc.or_(\n",
    "#     pc.or_(mask_false_mir, mask_false_sync),\n",
    "#     pc.or_(mask_false_z_adjusted, \n",
    "#            pc.or_(mask_null_mir, \n",
    "#                   pc.or_(mask_null_sync, mask_null_z_adjusted)))\n",
    "# )\n",
    "\n",
    "# # Apply the mask to filter the rows\n",
    "# filtered_table = table.filter(mask)\n",
    "\n",
    "# # Print the filtered rows for inspection\n",
    "# print(filtered_table.to_pandas())  # Convert to pandas for easier viewing in Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mir_generate_param sync z_adjusted            rec_file  \\\n",
      "0                  0    0          2        20240819V1r1   \n",
      "1                  0    0          2   241004_miniscopes   \n",
      "2                  0    0          2  20240916v1r1_18_53   \n",
      "\n",
      "                    scan_time date_folder  \n",
      "0  2024-10-15T16:51:45.975507  2024_10_03  \n",
      "1  2024-10-15T16:51:45.895409  2024_10_04  \n",
      "2  2024-10-15T16:51:45.942541  2024_10_07  \n"
     ]
    }
   ],
   "source": [
    "import pyarrow.compute as pc\n",
    "table = combined_df\n",
    "# Filter mir_generate_param == 0 and sync != 3\n",
    "filter_mask = pc.and_(\n",
    "    pc.equal(table['mir_generate_param'], '0'),\n",
    "    pc.not_equal(table['sync'], '3')\n",
    ")\n",
    "\n",
    "# Apply the filter and print the results\n",
    "filtered_table = table.filter(filter_mask)\n",
    "\n",
    "# Print each row of the filtered table\n",
    "print(filtered_table.to_pandas())  # This will display the filtered data in a familiar pandas-like format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "mir_generate_param: string\n",
       "sync: string\n",
       "z_adjusted: string\n",
       "rec_file: string\n",
       "scan_time: string\n",
       "date_folder: string\n",
       "----\n",
       "mir_generate_param: [[\"0\"],[\"0\"],...,[\"0\"],[\"0\"]]\n",
       "sync: [[\"0\"],[\"0\"],...,[\"0\"],[\"0\"]]\n",
       "z_adjusted: [[\"0\"],[\"0\"],...,[\"2\"],[\"2\"]]\n",
       "rec_file: [[\"20240717_PMC_r1_11_50\"],[\"20240717_PMC_r2_11_00\"],...,[\"20240916v1r1_18_53\"],[\"20240916v1r1_19_18\"]]\n",
       "scan_time: [[\"2024-10-15T15:47:18.408211\"],[\"2024-10-15T15:47:18.497773\"],...,[\"2024-10-15T15:47:18.700934\"],[\"2024-10-15T15:47:18.498807\"]]\n",
       "date_folder: [[\"2024_08_16\"],[\"2024_08_16\"],...,[\"2024_10_07\"],[\"2024_10_07\"]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.\n",
      "Frame count: 27900\n",
      "Frame count: 27300\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_29/20240717_PMCr2/2024_08_29_20240717_PMCr2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240707-PMC-r1/2024_09_18_20240707-PMC-r1_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 14243\n",
      "Frame count: 21969\n",
      "Frame count:Error opening video file.\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 27900\n",
      "Frame count: 30000\n",
      " 27300\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_03/20240819V1r2/2024_10_03_20240819V1r2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240717_PMCr1/2024_08_26_20240717_PMCr1_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240717_PMCr2/2024_08_26_20240717_PMCr2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819-V1-r2/2024_09_18_20240819-V1-r2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 28404\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_16/20240717_PMC_r1_11_50/2024_08_16_20240717_PMC_r1_11_50_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_16/20240717_PMC_r2_11_00/2024_08_16_20240717_PMC_r2_11_00_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 27900\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819_V1_r1_2/2024_09_18_20240819_V1_r1_2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 27900\n",
      "Frame count: 27900\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819_V1_r1/2024_09_18_20240819_V1_r1_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240730_PMCr2/2024_08_26_20240730_PMCr2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240717_PMCr1/folder_log.parquet with new status.Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_16/20240717_PMC_r1_11_50/folder_log.parquet with new status.Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819-V1-r2/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_16/20240717_PMC_r2_11_00/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240707-PMC-r1/folder_log.parquet with new status.Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_03/20240819V1r2/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_03/20240819V1r1/folder_log.parquet with new status.\n",
      "\n",
      "Found 0 calibration files.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_29/20240717_PMCr2/folder_log.parquet with new status.\n",
      "\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240730_PMCr2/folder_log.parquet with new status.\n",
      "Found 0 calibration files.\n",
      "\n",
      "Found 0 calibration files.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819_V1_r1/folder_log.parquet with new status.\n",
      "Found 0 calibration files.Found 0 calibration files.\n",
      "Found 0 calibration files.Found 0 calibration files.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_09_18/20240819_V1_r1_2/folder_log.parquet with new status.\n",
      "\n",
      "Found 0 calibration files.\n",
      "Found 0 calibration files.Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_08_26/20240717_PMCr2/folder_log.parquet with new status.\n",
      "Found 0 calibration files.\n",
      "\n",
      "Found 0 calibration files.\n",
      "\n",
      "Frame count: 27300\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1/2024_10_04_20240819V1r1_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 27300\n",
      "Error opening video file.\n",
      "mir_generate_param ran successfully.\n",
      "Frame count:Frame count:Error opening video file. \n",
      "27300\n",
      "Frame count: 27300\n",
      "mir_generate_param ran successfully. \n",
      "54300\n",
      "Frame count: 27300\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240916V1r1/2024_10_04_20240916V1r1_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 2530\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_17_55/2024_10_07_20240916v1r1_17_55_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count: 1766\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_21_05/2024_10_04_20240819V1r1_21_05_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_15_05_30min/2024_10_07_20240916v1r1_15_05_30min_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240916V1r2/2024_10_04_20240916V1r2_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Frame count:Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_20_10/2024_10_04_20240819V1r1_20_10_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      " 27300\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_19_18/2024_10_07_20240916v1r1_19_18_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Data saved to /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_21_40/2024_10_04_20240819V1r1_21_40_calib_before_label3d_dannce.mat\n",
      "mir_generate_param ran successfully.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_15_05_30min/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_21_05/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_17_55/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240916V1r1/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/241004_miniscopes/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240916V1r2/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_18_53/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_21_40/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_07/20240916v1r1_19_18/folder_log.parquet with new status.\n",
      "Updated Parquet file at /hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ/2024_10_04/20240819V1r1_20_10/folder_log.parquet with new status.\n"
     ]
    }
   ],
   "source": [
    "# too lazy to write general/reuseable codes, thus\n",
    "# below is only to process mir_generate_param\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from utlis.exe_engine_utlis.mir_generate_param_modu import mir_generate_param_z\n",
    "\n",
    "# Function to process each \"unit\" (rec_file) and update its status in the corresponding Parquet file\n",
    "def process_unit_and_update_status(rec_file_data, base_folder):\n",
    "    date_folder = rec_file_data['date_folder']\n",
    "    rec_file = rec_file_data['rec_file']\n",
    "    \n",
    "    # Generate the paths needed for processing\n",
    "    combined_path = os.path.join(base_folder, date_folder)\n",
    "    calib_path = rec_file_data['calib_path'] if 'calib_path' in rec_file_data else os.path.join(base_folder, 'calib_before')\n",
    "    \n",
    "    if not calib_path:  # Check for empty or None calib_path\n",
    "        print(f'No calib folder found. Aborting. {combined_path}/{rec_file}')\n",
    "        return\n",
    "    \n",
    "    output_file = f'{os.path.basename(date_folder)}_{rec_file}_{os.path.basename(calib_path)}_label3d_dannce.mat'\n",
    "\n",
    "    # Call your processing function\n",
    "    mir_generate_param_z(combined_path, calib_path, rec_file, output_file)\n",
    "    print(\"mir_generate_param ran successfully.\")\n",
    "\n",
    "    # After processing, update the status in the specific Parquet file\n",
    "    parquet_file_path = os.path.join(base_folder, date_folder, rec_file, \"folder_log.parquet\")\n",
    "\n",
    "    # Load the existing Parquet file\n",
    "    try:\n",
    "        table = pq.read_table(parquet_file_path)\n",
    "        df = table.to_pandas()  # Convert to pandas for easier manipulation\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Parquet file not found at {parquet_file_path}\")\n",
    "        return\n",
    "\n",
    "    # Update the status field (assuming 'sync' is the column)\n",
    "    df['mir_generate_param'] = '1'  # Set status to '1' for processed\n",
    "\n",
    "    # Add scan_time (or other updates)\n",
    "    df['scan_time'] = datetime.datetime.now().isoformat()\n",
    "\n",
    "    # Write the updated DataFrame back to the Parquet file\n",
    "    updated_table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(updated_table, parquet_file_path)\n",
    "\n",
    "    print(f\"Updated Parquet file at {parquet_file_path} with new status.\")\n",
    "\n",
    "# Function to handle parallel processing and status updates\n",
    "def parallel_process_and_update(filtered_table, base_folder):\n",
    "    # Convert PyArrow table to pandas DataFrame\n",
    "    filtered_df = filtered_table.to_pandas()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_unit_and_update_status, row._asdict(), base_folder)\n",
    "            for row in filtered_df.itertuples(index=False)\n",
    "        ]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Handle any exceptions\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing: {e}\")\n",
    "\n",
    "# Example function call\n",
    "# filtered_table = [...]  # Your filtered PyArrow table here\n",
    "# base_folder = '/path/to/your/base_folder'\n",
    "parallel_process_and_update(filtered_table, base_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "mir_generate_param: string\n",
      "sync: string\n",
      "z_adjusted: string\n",
      "rec_file: string\n",
      "scan_time: string\n",
      "date_folder: string\n",
      "----\n",
      "mir_generate_param: [[\"0\"],[\"0\"],...,[\"0\"],[\"0\"]]\n",
      "sync: [[\"3\"],[\"3\"],...,[\"1\"],[\"1\"]]\n",
      "z_adjusted: [[\"0\"],[\"0\"],...,[\"2\"],[\"2\"]]\n",
      "rec_file: [[\"1686940_left_right\"],[\"1686940_left_right_2\"],...,[\"20240916v1r1_18_53\"],[\"20240916v1r1_19_18\"]]\n",
      "scan_time: [[\"2024-10-15T15:47:18.496021\"],[\"2024-10-15T15:47:18.498828\"],...,[\"2024-10-15T16:38:36.504311\"],[\"2024-10-15T16:38:37.212976\"]]\n",
      "date_folder: [[\"2024_06_25\"],[\"2024_06_25\"],...,[\"2024_10_07\"],[\"2024_10_07\"]]\n"
     ]
    }
   ],
   "source": [
    "from utlis.scan_engine_utlis.scan_engine_utlis import read_all_parquet_files_auto_exclude\n",
    "base_folder = \"/hpc/group/tdunn/Bryan_Rigs/BigOpenField/24summ\"\n",
    "\"\"\"actually can use read_all_parquet_files in cluster probably, i do not have calib folders locally so need to handle this hhh\"\"\"\n",
    "\n",
    "# Example usage\n",
    "# base_folder = \"/path/to/your/base_folder\"  # Replace with your base folder\n",
    "combined_df = read_all_parquet_files_auto_exclude(base_folder, exclude_columns = ['calib_files']\n",
    ")\n",
    "\n",
    "# Display or use the combined DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mir_generate_param sync z_adjusted                  rec_file  \\\n",
      "0                   0    1          0     20240717_PMC_r1_11_50   \n",
      "1                   0    1          0     20240717_PMC_r2_11_00   \n",
      "2                   0    1          0            20240717_PMCr1   \n",
      "3                   0    1          0            20240717_PMCr2   \n",
      "4                   0    1          0            20240730_PMCr2   \n",
      "5                   0    1          0            20240717_PMCr2   \n",
      "6                   0    1          2           20240707-PMC-r1   \n",
      "7                   0    1          2            20240819-V1-r2   \n",
      "8                   0    1          2            20240819_V1_r1   \n",
      "9                   0    1          2          20240819_V1_r1_2   \n",
      "10                  0    1          2              20240819V1r1   \n",
      "11                  0    1          2              20240819V1r2   \n",
      "12                  0    1          2              20240819V1r1   \n",
      "13                  0    1          2        20240819V1r1_20_10   \n",
      "14                  0    1          2        20240819V1r1_21_05   \n",
      "15                  0    1          2        20240819V1r1_21_40   \n",
      "16                  0    1          2              20240916V1r1   \n",
      "17                  0    1          2              20240916V1r2   \n",
      "18                  0    1          2         241004_miniscopes   \n",
      "19                  0    1          2  20240916v1r1_15_05_30min   \n",
      "20                  0    1          2        20240916v1r1_17_55   \n",
      "21                  0    1          2        20240916v1r1_18_53   \n",
      "22                  0    1          2        20240916v1r1_19_18   \n",
      "\n",
      "                     scan_time date_folder  \n",
      "0   2024-10-15T16:38:33.871895  2024_08_16  \n",
      "1   2024-10-15T16:38:33.874083  2024_08_16  \n",
      "2   2024-10-15T16:38:33.879673  2024_08_26  \n",
      "3   2024-10-15T16:38:32.886724  2024_08_26  \n",
      "4   2024-10-15T16:38:33.875176  2024_08_26  \n",
      "5   2024-10-15T16:38:33.877002  2024_08_29  \n",
      "6   2024-10-15T16:38:33.870078  2024_09_18  \n",
      "7   2024-10-15T16:38:32.866373  2024_09_18  \n",
      "8   2024-10-15T16:38:33.882017  2024_09_18  \n",
      "9   2024-10-15T16:38:33.876034  2024_09_18  \n",
      "10  2024-10-15T16:38:32.931107  2024_10_03  \n",
      "11  2024-10-15T16:38:33.873681  2024_10_03  \n",
      "12  2024-10-15T16:38:36.376836  2024_10_04  \n",
      "13  2024-10-15T16:38:37.099072  2024_10_04  \n",
      "14  2024-10-15T16:38:36.730921  2024_10_04  \n",
      "15  2024-10-15T16:38:37.193940  2024_10_04  \n",
      "16  2024-10-15T16:38:36.854056  2024_10_04  \n",
      "17  2024-10-15T16:38:36.743841  2024_10_04  \n",
      "18  2024-10-15T16:38:36.751361  2024_10_04  \n",
      "19  2024-10-15T16:38:36.518412  2024_10_07  \n",
      "20  2024-10-15T16:38:36.823060  2024_10_07  \n",
      "21  2024-10-15T16:38:36.504311  2024_10_07  \n",
      "22  2024-10-15T16:38:37.212976  2024_10_07  \n"
     ]
    }
   ],
   "source": [
    "import pyarrow.compute as pc\n",
    "table = combined_df\n",
    "# Filter mir_generate_param == 0 and sync != 3\n",
    "filter_mask = pc.and_(\n",
    "    pc.equal(table['mir_generate_param'], '0'),\n",
    "    pc.not_equal(table['sync'], '3'),\n",
    "    pc.not_equal(table['sync'], '3')\n",
    ")\n",
    "\n",
    "# Apply the filter and print the results\n",
    "filtered_table = table.filter(filter_mask)\n",
    "\n",
    "# Print each row of the filtered table\n",
    "print(filtered_table.to_pandas())  # This will display the filtered data in a familiar pandas-like format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too lazy to write general/reuseable codes, thus\n",
    "# below is only to process mir_generate_param\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from utlis.exe_engine_utlis.mir_generate_param_modu import mir_generate_param_z\n",
    "\n",
    "# Function to process each \"unit\" (rec_file) and update its status in the corresponding Parquet file\n",
    "def process_unit_and_update_status(rec_file_data, base_folder):\n",
    "    date_folder = rec_file_data['date_folder']\n",
    "    rec_file = rec_file_data['rec_file']\n",
    "    \n",
    "    # Generate the paths needed for processing\n",
    "    combined_path = os.path.join(base_folder, date_folder)\n",
    "    calib_path = rec_file_data['calib_path'] if 'calib_path' in rec_file_data else os.path.join(base_folder, 'calib_before')\n",
    "    \n",
    "    if not calib_path:  # Check for empty or None calib_path\n",
    "        print(f'No calib folder found. Aborting. {combined_path}/{rec_file}')\n",
    "        return\n",
    "    \n",
    "    output_file = f'{os.path.basename(date_folder)}_{rec_file}_{os.path.basename(calib_path)}_label3d_dannce.mat'\n",
    "\n",
    "    # Call your processing function\n",
    "    mir_generate_param_z(combined_path, calib_path, rec_file, output_file)\n",
    "    print(\"mir_generate_param ran successfully.\")\n",
    "\n",
    "    # After processing, update the status in the specific Parquet file\n",
    "    parquet_file_path = os.path.join(base_folder, date_folder, rec_file, \"folder_log.parquet\")\n",
    "\n",
    "    # Load the existing Parquet file\n",
    "    try:\n",
    "        table = pq.read_table(parquet_file_path)\n",
    "        df = table.to_pandas()  # Convert to pandas for easier manipulation\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Parquet file not found at {parquet_file_path}\")\n",
    "        return\n",
    "\n",
    "    # Update the status field (assuming 'sync' is the column)\n",
    "    df['mir_generate_param'] = '1'  # Set status to '1' for processed\n",
    "\n",
    "    # Add scan_time (or other updates)\n",
    "    df['scan_time'] = datetime.datetime.now().isoformat()\n",
    "\n",
    "    # Write the updated DataFrame back to the Parquet file\n",
    "    updated_table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(updated_table, parquet_file_path)\n",
    "\n",
    "    print(f\"Updated Parquet file at {parquet_file_path} with new status.\")\n",
    "\n",
    "# Function to handle parallel processing and status updates\n",
    "def parallel_process_and_update(filtered_table, base_folder):\n",
    "    # Convert PyArrow table to pandas DataFrame\n",
    "    filtered_df = filtered_table.to_pandas()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_unit_and_update_status, row._asdict(), base_folder)\n",
    "            for row in filtered_df.itertuples(index=False)\n",
    "        ]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                future.result()  # Handle any exceptions\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing: {e}\")\n",
    "\n",
    "# Example function call\n",
    "# filtered_table = [...]  # Your filtered PyArrow table here\n",
    "# base_folder = '/path/to/your/base_folder'\n",
    "parallel_process_and_update(filtered_table, base_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BBOP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
