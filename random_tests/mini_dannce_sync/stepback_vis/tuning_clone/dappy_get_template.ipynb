{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115it [00:09, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centering poses to mid spine ...\n",
      "Rotating spine to xz plane ... \n"
     ]
    }
   ],
   "source": [
    "from neuroposelib import read\n",
    "from neuroposelib import vis\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import Video\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from neuroposelib import preprocess\n",
    "from neuroposelib import write\n",
    "from neuroposelib import features\n",
    "\n",
    "# analysis_key = \"tutorial\"\n",
    "# config = read.config(\"../configs/\" + analysis_key + \".yaml\")\n",
    "config = read.config('/home/lq53/mir_repos/BBOP/random_tests/dappy_backups/iter_com_features/mir_2.yaml')\n",
    "# pose, ids = read.pose_h5(config[\"data_path\"] + \"demo_mouse.h5\")\n",
    "\n",
    "\n",
    "connectivity = read.connectivity(\n",
    "    path=config[\"skeleton_path\"], skeleton_name=config[\"skeleton_name\"]\n",
    ")\n",
    "\n",
    "# Make out_path\n",
    "Path(config[\"out_path\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# meta, meta_by_frame = read.meta(config[\"data_path\"] + \"demo_meta.csv\", id=ids)\n",
    "pose, ids, meta, meta_by_frame = read.pose_from_meta(\n",
    "    path=config[\"meta_path\"], connectivity=connectivity, key=\"Prediction_path\", file_type=\"dannce\"\n",
    ")\n",
    "\n",
    "Path(config[\"out_path\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# from neuroposelib import write\n",
    "\n",
    "# # write.pose_h5(pose_aligned, ids, config[\"data_path\"] + \"pose_aligned.h5\")\n",
    "# write.pose_h5(pose,ids, config['out_path'] + 'pose_merged_newcol.h5')\n",
    "# # Read pose_merged.h if already saved\n",
    "# # pose, ids = read.pose_h5(config[\"data_path\"] + \"pose_merged.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# vis.pose.arena3D(\n",
    "#     pose,\n",
    "#     connectivity,\n",
    "#     frames=[1000, 500000],\n",
    "#     N_FRAMES=150,\n",
    "#     dpi=100,\n",
    "#     VID_NAME=\"raw.mp4\",\n",
    "#     SAVE_ROOT=config[\"out_path\"],\n",
    "# )\n",
    "\n",
    "# Provide the mid-spine and the mid-spine -> front-spine indices.\n",
    "# pose = preprocess.rotate_spine(preprocess.center_spine(pose_aligned, keypt_idx=4), keypt_idx=[4, 3])\n",
    "pose = preprocess.rotate_spine(preprocess.center_spine(pose, keypt_idx=4), keypt_idx=[4, 3])\n",
    "\n",
    "write.pose_h5(pose,ids, config['out_path'] + 'pose_merged_newcol.h5')\n",
    "\n",
    "# vis.pose.arena3D(\n",
    "#     pose,\n",
    "#     connectivity,\n",
    "#     frames=[50000],\n",
    "#     N_FRAMES=150,\n",
    "#     dpi=100,\n",
    "#     VID_NAME=\"centered.mp4\",\n",
    "#     SAVE_ROOT=config[\"out_path\"],\n",
    "# )\n",
    "\n",
    "# # Video(url=config[\"out_path\"] + \"vis_centered.mp4\", width=600, height=600)\n",
    "# # Calculating joint angles\n",
    "# angles, angle_labels = features.get_angles(pose, connectivity.angles)\n",
    "\n",
    "# # Reshape pose to get egocentric pose features\n",
    "# ego_pose, labels = features.get_ego_pose(pose, connectivity.joint_names)\n",
    "\n",
    "# # Write\n",
    "# write.features_h5(angles, labels, path=config[\"out_path\"] + \"angels.h5\")\n",
    "# write.features_h5(ego_pose, labels, path=config[\"out_path\"] + \"ego_pose.h5\")\n",
    "# print(\"saved\")\n",
    "# # write.features_h5(angles, angle_labels, path=config[\"out_path\"] + \"angles_calc.h5\")\n",
    "\n",
    "# # Read\n",
    "# # features, labels = read.features_h5(path=config[\"out_path\"] + \"postural_feats.h5\")\n",
    "\n",
    "# t = time.time()\n",
    "\n",
    "# pc_feats, pc_labels = features.pca(\n",
    "#     angles, angle_labels, categories=[\"ang\"], n_pcs=5, method=\"fbpca\"\n",
    "# )\n",
    "# write.features_h5(pc_feats, pc_labels, path=config[\"out_path\"] + \"_pca.h5\")\n",
    "# print(\"PCA time: \" + str(time.time() - t))\n",
    "# del angles, angle_labels\n",
    "# del ego_pose, labels\n",
    "\n",
    "# from scipy import signal\n",
    "# M = 100\n",
    "# w0 = 5\n",
    "# s = w0*90/(2*np.pi*25) #30, 90?\n",
    "# morlet_wavelet = signal.morlet2(M, s, w0)\n",
    "# plt.plot(morlet_wavelet.imag, label='Imaginary')\n",
    "# plt.plot(morlet_wavelet.real, label='Real')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# wlet_feats, wlet_labels = features.wavelet(\n",
    "#     pc_feats, pc_labels, ids, f_s=30, freq=np.linspace(1, 25, 25), w0=5\n",
    "# )\n",
    "\n",
    "# write.features_h5(wlet_feats, wlet_labels, path=config[\"out_path\"] + \"_wavelets.h5\")\n",
    "\n",
    "\n",
    "# # PCA on wavelet features\n",
    "# pc_wlet, pc_wlet_labels = features.pca(\n",
    "#     wlet_feats,\n",
    "#     wlet_labels,\n",
    "#     # categories=[\"wlet_ego_euc\"],\n",
    "#     categories=[\"wlet_ang\"],\n",
    "#     n_pcs=5,\n",
    "#     method=\"fbpca\",\n",
    "# )\n",
    "\n",
    "# del wlet_feats, wlet_labels\n",
    "# pc_feats = np.hstack((pc_feats, pc_wlet))\n",
    "# pc_labels += pc_wlet_labels\n",
    "# del pc_wlet, pc_wlet_labels\n",
    "\n",
    "# write.features_h5(\n",
    "#     pc_feats, pc_labels, path=\"\".join([config[\"out_path\"], \"_pca_on_wavelets.h5\"])\n",
    "# )\n",
    "\n",
    "\n",
    "# from neuroposelib import DataStruct as ds\n",
    "\n",
    "# data_obj = ds.DataStruct(\n",
    "#     pose=pose,\n",
    "#     id=ids,\n",
    "#     meta=meta,\n",
    "#     meta_by_frame=meta_by_frame,\n",
    "#     connectivity=connectivity,\n",
    "# )\n",
    "\n",
    "# data_obj.features = pc_feats\n",
    "# # When using high framerate data, downsampling may be necessary in order to \n",
    "# # discover granular structure in embedding\n",
    "# data_obj = data_obj[:: config[\"downsample\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3539000, 22, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroposelib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
